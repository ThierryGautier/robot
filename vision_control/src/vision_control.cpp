#if 1
/* system include */
#include <iostream>
#include <ctype.h>
#include <errno.h>
#include <mqueue.h>

/* opencv include */
#include "opencv2/videoio.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/opencv.hpp"
#include "opencv2/core/ocl.hpp"
#include "opencv2/objdetect.hpp"

extern "C" {
  #include "stdtype.h"
  #include "supervisor.h"
  #include "com.h"
}

using namespace cv;
using namespace std;

/** 25 fps is warranty with Philips usb 2.0 webcam */
#define S32_WIDTH_SIZE  160
#define S32_HEIGHT_SIZE 120

/** 10 fps is warranty with Philips usb 2.0 webcam */
//#define S32_WIDTH_SIZE  320
//#define S32_HEIGHT_SIZE 240

/** 3 fps is warranty with Philips usb 2.0 webcam */
//#define S32_WIDTH_SIZE  640
//#define S32_HEIGHT_SIZE 480


//#define LOG_ENABLE
#define LOG_WINDOWS_ENABLE

// Convert to string
#define SSTR( x ) static_cast< std::ostringstream & >( \
                  ( std::ostringstream() << std::dec << x ) ).str()

/** Global variables */
String frontface_cascade_name = "/usr/local/share/opencv4/haarcascades/haarcascade_frontalface_alt.xml";
String upperbody_cascade_name = "/usr/local/share/opencv4/haarcascades/haarcascade_upperbody.xml";
CascadeClassifier frontface_cascade;
CascadeClassifier upperbody_cascade;

static Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor

static SPR_stVisionEvent gstFaceEvent;
static SPR_stVisionEvent gstPreviousFaceEvent;
static SPR_stVisionEvent gstBodyEvent;
static SPR_stVisionEvent gstPreviousBodyEvent;

/** @function DisplayFPSProcess */
static void DisplayFPSProcess( Mat frame,double fps)
{
    Mat frame_fps;
    frame.copyTo(frame_fps);
    // Display FPS on frame
    putText(frame_fps, "FPS : " + SSTR(int(fps)), Point(0,20), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(50,170,50), 2);

    //show the fps
    imshow("fps", frame_fps);
}


/** @function BackgroundSubtractorProcess */
static void BackgroundSubtractorProcess( Mat frame)
{
    static bool bInitIsDone = false;
    //vars used to background subtractor

    Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method

    if(bInitIsDone == false)
    {
        //create Background Subtractor objects
        pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach
        bInitIsDone = true;
    }
    //update the background model
    pMOG2->apply(frame, fgMaskMOG2,(double)0.1f);

#ifdef LOG_WINDOWS_ENABLE
    //show the fg masks
    imshow("FG Mask MOG 2", fgMaskMOG2);
#endif
}

/** @function Filter2DProcess */
static void Filter2DProcess( Mat frame)
{
    Mat frame_filter3;
    Mat frame_filter5;
    Mat Kernel3 = (Mat_<double>(3,3) << -1, -1, -1,
                                        -1,  8, -1,
                                        -1, -1, -1);

    Mat Kernel5 = (Mat_<double>(5,5) << -1, -1, -1, -1, -1,
                                        -1, -2, -2, -2, -1,
                                        -1, -2, 32, -2, -1,
                                        -1, -2, -2, -2, -1,
                                        -1, -1, -1, -1, -1);

/*filter
CV_EXPORTS_W void filter2D( InputArray src, OutputArray dst, int ddepth,
                            InputArray kernel, Point anchor = Point(-1,-1),
                            double delta = 0, int borderType = BORDER_DEFAULT )
*/
    filter2D(frame,frame_filter3,-1,Kernel3,Point(-1,-1),0,BORDER_DEFAULT);

#ifdef LOG_WINDOWS_ENABLE
    // Show after filter traitment
    imshow("Filter3", frame_filter3 );
#endif

    filter2D(frame,frame_filter5,-1,Kernel5,Point(-1,-1),0,BORDER_DEFAULT);

#ifdef LOG_WINDOWS_ENABLE
    // Show after filter traitment
    imshow("Filter5", frame_filter5 );
#endif
}

/** @function DetectAndDisplayProcess */
static void DetectAndDisplayProcess( Mat frame ,SPR_stVisionEvent* stFaceEvent, SPR_stVisionEvent* stBodyEvent)
{
    std::vector<Rect> faces;
    std::vector<Rect> bodies;

    Mat frame_gray;
    Mat frame_faces;
    Mat frame_bodies;

    frame.copyTo(frame_faces);
    frame.copyTo(frame_bodies);

    //convert between RGB/BGR and grayscale
    cvtColor( frame, frame_gray , COLOR_BGR2GRAY );

    //equalizes the histogram
    equalizeHist( frame_gray, frame_gray );

    /* Detect faces */
    frontface_cascade.detectMultiScale( frame_gray, faces, 1.1, 2, 0|CASCADE_SCALE_IMAGE, Size(30, 30) );

    /* trace elipse around all faces detected */
    for ( size_t i = 0; i < faces.size(); i++ )
    {
        Point center( faces[i].x + faces[i].width/2, faces[i].y + faces[i].height/2 );
        ellipse( frame_faces, center, Size( faces[i].width/2, faces[i].height/2 ), 0, 0, 360, Scalar( 255, 0, 255 ), 4, 8, 0 );

        // Display position of the center
        putText(frame_faces, "POSITION X: " + SSTR(center.x), Point(0,20+i*40), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(50,170,50), 2);
        putText(frame_faces, "POSITION Y: " + SSTR(center.y), Point(0,40+i*40), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(50,170,50), 2);

    }
#ifdef LOG_WINDOWS_ENABLE
    // Show face detection
    imshow("face_detection", frame_faces );
#endif
    /* Detect bodies */
    upperbody_cascade.detectMultiScale( frame_gray, bodies, 1.1, 2, 0|CASCADE_SCALE_IMAGE, Size(30, 30) );

    /* trace elipse around all bodies detected */
    for ( size_t i = 0; i < bodies.size(); i++ )
    {
        Point center( bodies[i].x + bodies[i].width/2, bodies[i].y + bodies[i].height/2 );
        ellipse( frame_bodies, center, Size( bodies[i].width/2, bodies[i].height ), 0, 0, 360, Scalar( 255, 255, 0 ), 4, 8, 0 );

        // Display position of the center
        putText(frame_bodies, "POSITION X: " + SSTR(center.x), Point(0,20*i+40), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(50,170,50), 2);
        putText(frame_bodies, "POSITION Y: " + SSTR(center.y), Point(0,40*i+40), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(50,170,50), 2);

    }
#ifdef LOG_WINDOWS_ENABLE
    // Show body detection
    imshow("body_detection", frame_bodies );
#endif

    /* send first face event detection */
    if( faces.size() > 0)
    {
        Point center( faces[0].x + faces[0].width/2, faces[0].y + faces[0].height/2 );
        stFaceEvent->eTypeOfEvent = SPR_eFaceDetection;
        stFaceEvent->u32TimeOfVisionEventIn_us = 0; //TODO
        stFaceEvent->f32X =  (FL32)center.x/(FL32)S32_WIDTH_SIZE;
        stFaceEvent->f32Y =  (FL32)center.y/(FL32)S32_HEIGHT_SIZE;
        stFaceEvent->f32Width  =  (FL32)faces[0].width/(FL32)S32_WIDTH_SIZE;
        stFaceEvent->f32Height =  (FL32)faces[0].height/(FL32)S32_HEIGHT_SIZE;
        printf("f32X=%f f32Y=%f f32Width=%f f32height=%f\n",stFaceEvent->f32X ,stFaceEvent->f32Y,stFaceEvent->f32Width,stFaceEvent->f32Height);
    }
    else
    {
        stFaceEvent->eTypeOfEvent = SPR_eNoEvent;
        stFaceEvent->u32TimeOfVisionEventIn_us = 0;
        stFaceEvent->f32X =  0;
        stFaceEvent->f32Y =  0;
    }

    /* send first body event detection */
    if( bodies.size() > 0)
    {
        Point center( bodies[0].x + bodies[0].width/2, bodies[0].y + bodies[0].height/2 );
        stBodyEvent->eTypeOfEvent = SPR_eBodyDetection;
        stBodyEvent->u32TimeOfVisionEventIn_us = 0; //TODO
        stBodyEvent->f32X =  (FL32)center.x/(FL32)S32_WIDTH_SIZE;
        stBodyEvent->f32Y =  (FL32)center.y/(FL32)S32_HEIGHT_SIZE;
    }
    else
    {
        stBodyEvent->eTypeOfEvent = SPR_eNoEvent;
        stBodyEvent->u32TimeOfVisionEventIn_us = 0;
        stBodyEvent->f32X =  0;
        stBodyEvent->f32Y =  0;
    }
}

/** @function DetectAndDisplayProcess */
static void TrackingProcess( Mat frame ,BOOL bFisrtCall)
{
    static Mat roi, hsv_roi, mask;
    static float range_[] = {0, 180};
    static const float* range[] = {range_};
    static Mat roi_hist;
    static int histSize[] = {180};
    static int channels[] = {0};
    
    static Rect track_window;
    static TermCriteria term_crit;
    static BOOL bTackingInitDone = FALSE;
    
    if(bFisrtCall == TRUE)
    {
        // setup initial location of window
        track_window.x = gstFaceEvent.f32X*S32_WIDTH_SIZE - gstFaceEvent.f32Width*S32_WIDTH_SIZE/2;
        track_window.y = gstFaceEvent.f32Y*S32_HEIGHT_SIZE  - gstFaceEvent.f32Height*S32_HEIGHT_SIZE/2;
        track_window.width = gstFaceEvent.f32Width*S32_WIDTH_SIZE;
        track_window.height = gstFaceEvent.f32Height*S32_HEIGHT_SIZE;

        // set up the ROI for tracking
        roi = frame(track_window);

        cvtColor(roi, hsv_roi, COLOR_BGR2HSV);
        inRange(hsv_roi, Scalar(0, 60, 32), Scalar(180, 255, 255), mask);

        calcHist(&hsv_roi, 1, channels, mask, roi_hist, 1, histSize, range);
        normalize(roi_hist, roi_hist, 0, 255, NORM_MINMAX);

        // Setup the termination criteria, either 10 iteration or move by atleast 1 pt
        term_crit.type = TermCriteria::EPS | TermCriteria::COUNT;
        term_crit.maxCount = 10;
        term_crit.epsilon = 1;
        
        bTackingInitDone = TRUE;
    }
    else if(bTackingInitDone == TRUE)
    {
        Mat hsv, dst;
        cvtColor(frame, hsv, COLOR_BGR2HSV);
        calcBackProject(&hsv, 1, channels, roi_hist, dst, range);
        // apply camshift to get the new location
        RotatedRect rot_rect = CamShift(dst, track_window, term_crit);

#ifdef LOG_WINDOWS_ENABLE
        // Draw it on image
        Point2f points[4];
        rot_rect.points(points);
        for (int i = 0; i < 4; i++)
            line(frame, points[i], points[(i+1)%4], 255, 2);
        imshow("tracking", frame);
#endif
    }
}

/** @function main */
int main( int argc, const char**argv )
{
    VideoCapture capture;
    Mat FrameSource;
    Mat FrameReadyForAnalysis;

    int VideoDeviceID;
    
    double dWidth;
    double dHeight;
    double dFPS;
    double oldtimer, timer,fps;
    
    
    /* read parameters required for vision_control */
    CommandLineParser parser(argc,argv,
                            "{help h|         |vision_control camera=1 }"
                            "{camera|1        |Camera = device number ref /dev/video<X> for linux. }");
   
    parser.about("\nThis program is able to detect face and body and track it"
                 "It's required a camera connected to your computer or your single board computer"); 
 
    parser.printMessage();
    
    VideoDeviceID = parser.get<int>("camera"); 
    cout << "VideoDeviceID=" << VideoDeviceID << "\n" << endl;
    
    /* init message queue required to send vision events to supervisor process */
    COM_InitCommunicationWithSupervisorProcess();

    /* define parameter to fix image resolution */
    Size size(S32_WIDTH_SIZE,S32_HEIGHT_SIZE);//the dst image size,e.g.S32_WIDTH_SIZExS32_HEIGHT_SIZE

    //-- 1. Load the cascades
    if( !frontface_cascade.load( frontface_cascade_name ) )
    {
        cout << "--(!)Error loading front face cascade\n" << endl;
        return -1;
    };
    if( !upperbody_cascade.load( upperbody_cascade_name ) )
    {
        cout << "--(!)Error loading upper body cascade\n" << endl;
        return -1;
    };

    
    //-- 2. Read the video stream
    capture.open( VideoDeviceID );
    if ( ! capture.isOpened() ) { printf("--(!)Error opening video capture\n"); return -1; }

    //get th resolution of the web camera
    dWidth = capture.get(CAP_PROP_FRAME_WIDTH);
    dHeight = capture.get(CAP_PROP_FRAME_HEIGHT);
    dFPS = capture.get(CAP_PROP_FPS);
    cout << "\nThis is the resolution of the first video device detected:\n"
            "dWidth =" << dWidth << "\n"
            "dHeight=" << dHeight << "\n"
            "dFPS   =" << dFPS << "\n"
            << endl;


    /* configure capture to reduce CPU usage and warranty fix frequency for FPS (reduce USB 2.0 usage)
     * - detect face
     * - detect body
     */
    capture.set(CAP_PROP_FRAME_WIDTH,S32_WIDTH_SIZE);
    capture.set(CAP_PROP_FRAME_HEIGHT,S32_HEIGHT_SIZE);

    dWidth = capture.get(CAP_PROP_FRAME_WIDTH);
    dHeight = capture.get(CAP_PROP_FRAME_HEIGHT);
    dFPS = capture.get(CAP_PROP_FPS);
    cout << "\nThis is the resolution used:\n"
            "dWidth =" << dWidth << "\n"
            "dHeight=" << dHeight << "\n"
            "dFPS   =" << dFPS << "\n"
            << endl;


    //start infinite loop of vision control process
    cout << "\nThis is vision control process"
            "\nUsing OpenCV version " << CV_VERSION << endl;
    while (1)
    {
        /* get frame */
        if(capture.read(FrameSource))
        {
            // Start timer
            timer = (double)getTickCount();
            // Calculate Frames per second (FPS)
            fps = (getTickFrequency()/(timer -oldtimer));
            oldtimer = timer;
#ifdef LOG_ENABLE
            FL64 dPos = capture.get(CAP_PROP_POS_MSEC);
            cout << "dPos:" << dPos << "ms, fps:" << fps << endl;
#endif
            if( FrameSource.empty() )
            {
                cout << " --(!) No captured frame -- Break!" << endl;
                break;
            }

            if((dWidth != S32_WIDTH_SIZE ) OR (dHeight != S32_HEIGHT_SIZE ))
                /* reduce size of the image */
                resize(FrameSource,FrameReadyForAnalysis,size);//resize image
            else
                FrameReadyForAnalysis = FrameSource;

            /*-- 3. Apply the classifier to the frame */
            
//#ifdef LOG_WINDOWS_ENABLE
            DisplayFPSProcess(FrameReadyForAnalysis,fps);
//#endif
            Filter2DProcess(FrameReadyForAnalysis);
            BackgroundSubtractorProcess(FrameReadyForAnalysis);
            DetectAndDisplayProcess( FrameReadyForAnalysis,
                                     &gstFaceEvent,
                                     &gstBodyEvent);

            /* start tracking process when rising edge of face detection */
            TrackingProcess(FrameReadyForAnalysis,(gstFaceEvent.eTypeOfEvent == SPR_eFaceDetection) AND
                                                  (gstPreviousFaceEvent.eTypeOfEvent == SPR_eNoEvent));

            /* send an event to supervisor if face or body is detected or if lost */
            if((gstFaceEvent.eTypeOfEvent != SPR_eNoEvent) OR
               ((gstFaceEvent.eTypeOfEvent == SPR_eNoEvent) AND (gstPreviousFaceEvent.eTypeOfEvent != SPR_eNoEvent))
              )
            {
                 COM_SendVisionEventThroughMsgQueue(gstFaceEvent);
                 gstPreviousFaceEvent = gstFaceEvent;
            }
            
            if((gstBodyEvent.eTypeOfEvent != SPR_eNoEvent) OR
               ((gstBodyEvent.eTypeOfEvent == SPR_eNoEvent) AND (gstPreviousBodyEvent.eTypeOfEvent != SPR_eNoEvent))
              )
            {
                COM_SendVisionEventThroughMsgQueue(gstBodyEvent);
                gstPreviousBodyEvent = gstBodyEvent;
            }
            //get the input from the keyboard, required to see frames
            waitKey( 20 );
        }
    }
    return 0;
}
#endif
